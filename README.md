# Blazor Benchmarks

This repo's contents are generated by exporting [the `E2EPerformance` sample](https://github.com/aspnet/Blazor/tree/master/benchmarks/Microsoft.AspNetCore.Blazor.E2EPerformance) from the [Blazor repo](https://github.com/aspnet/Blazor/).

The reason for having this exported copy in a separate repo is just to make it easier to run without having to build Blazor itself. It also makes it easier to track changes in the measured perf numbers over time.

## How to run

Clone this repo, then host it in any static-file web server. For example, to use Node's `http-server`, do this:

```
npm install -g http-server
cd blazor-benchmarks
http-server
```

Now open the served app in your web browser (e.g., http://localhost:8080, if you're using `http-server`), and click on the green **Run all** button.

## Testing Mono optimizations

The Mono binaries are at:

* `_framework\wasm\mono.wasm`
* `_framework\wasm\mono.js`
* `_framework\_bin\*.dll` (the .NET BCL)

So, if you want to test a different version of Mono against these benchmarks, you can just replace those files (usually just `mono.wasm` and `mono.js`) in your local copy with newly-built ones, then run again.

## Accuracy and Consistency

Benchmarking tools need to account for various external factors that can affect measured execution times, including:

* Unrelated garbage collections (here, on either the .NET or JS side)
* Level of cache-warmedness
* Dynamic CPU throttling

An established method for producing useful and consistent results is to estimate the *best-case* timings for each operation. That's what we're doing here: we run each scenario as many times as possible for a while, and report the fastest successful run time. Hopefully, on at least one run, there will be no GCs and the CPU will be running at full speed.

As a result, the timings reported here tend to be consistent to within a few percent.

Real-world execution times will sometimes be longer (because of GC and cold caches), but our goal here is to produce timings that can meaningfully be compared across framework and runtime versions.
